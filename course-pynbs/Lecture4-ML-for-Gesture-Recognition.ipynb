{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using jupyter notebook ...\n",
    "\n",
    "Two choices: \n",
    "1. **Open** this notebook and follow along the presentation\n",
    "    * Open terminal\n",
    "    * Type `jupyter-notebook Introduction_Machine_Learning.ipynb`\n",
    "2. **Create** your own notebook and reproduce the different steps (warning!)\n",
    "    * Open terminal\n",
    "    * Type `jupyter-notebook My_ML_Notebook.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start by **importing** the basic libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "<!-- MarkdownTOC autolink=true autoanchor=true bracket=round -->\n",
    "\n",
    "- [Machine Learning](#machinelearning)\n",
    "- [Technology: Jupyter Notebook, Sklearn](#technology)\n",
    "- [Toy Example in Machine Learning: the Iris Dataset](#toyexample)\n",
    "    - [Dataset description](#toyex_description)\n",
    "    - [Visualising Dataset](#toyex_visualising)\n",
    "    - [Training a Classifier on the Dataset](#toyex_training)\n",
    "    - [Testing a Classifier on the Dataset](#toyex_testing)\n",
    "    - [Assessing Training: Decision Boundaries](#toyex_boundaries)\n",
    "    - [Binary vs. Multiclass Problem](#toyex_multiclass)\n",
    "- [Gesture Recognition](#gr)\n",
    "    - [Visualising Dataset](#gr_visualising)\n",
    "    - [Training and Testing](#gr_training_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"machinelearning\"></a>\n",
    "# Machine Learning\n",
    "\n",
    "Machine learning has become recently a hot topic present in scientific literature as well as in the general public literature. Roughly saying, machine learning is *way* for computer to learn from data, and consequently, has been  at the heart of artificial intelligence algorithms. ML is nowadays already in many of the products we use Today from recommendation systems able to provide personnalized recommendations for filems (Netflix), music (Apple Music) or more general products (Amazon). Machine learning is also widely used to filters our spam, to recognise voice in personnal assistants, etc. \n",
    "\n",
    "A formal definition of **machine learning** (ML) can be: a set of methods that can **automatically detect patterns** in data, and then use the uncovered patterns to **predict future data** (*from Machine Learning: A Probabilistic Perspective (Murphy 2012)*)\n",
    "\n",
    "## Types of learning\n",
    "\n",
    "What are the types of \"learning\"? In ML literature, there are several types of learning, the three main types are: supervised learning, unsupervised learning and reinforcement learning. \n",
    "\n",
    "In supervised learning, you have access to a dataset where each datapoint, considered as an *input*, has an associated known output, that can be discrete (like a *label*) or continuous. The goal of a supervised learning algorithm is to learn the relationship between the inputs and their associated outputs. In case the outputs are discrete (*labels*) we call the task **classification**, in case the outputs are continous, the task is called **regression**. \n",
    "\n",
    "In unsupervised learning, you have acess to a dataset where there are only *inputs* (datapoints without associated labels or some values). The goal of an unsupervised learning algorithm is then to infer from these data the underlying structure. This task is usually harder than supervised learning. \n",
    "\n",
    "Reinforcement learning is a different paradigm: the learning occurs through interaction with the environment. In reinforcement learning, an agent takes actions in an environment such as to maximize some cumulative rewards. Each action taken produces a reward that the agent takes into account in order to assess the \"quality\" of the action. \n",
    "\n",
    "\n",
    "## Phases\n",
    "\n",
    "In ML, we usually consider two phases: **learning** then **testing**. **Training** an algorithm in machine learning means detecting patterns in a dataset. **Testing** an algorithm means predicting future data, that is generalizing the uncovered trained patterns to new datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"technology\"></a>\n",
    "# Technology: Jupyter Notebook, Sklearn\n",
    "\n",
    "At this stage of the course, you should have installed Python 3, Jupyter Notebook and all the useful lirbaries used in this course (like sklearn). If not, please refer to the README.md \n",
    "\n",
    "<a name=\"technology_intro\"></a>\n",
    "## Quick introduction to jupyter notebook\n",
    "\n",
    "### Cell\n",
    "Cell in jupyter notebook is where we write code or text that can be executed (or interpreted). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries \n",
    "\n",
    "At this stage, you cannot do much except calling the basic python functions such as '+' or '-' (and others). To be able to use additional functions we use libraries. Libraries are collections of functions that can be called in python programs. In order to use the functions included in a library, you first have to `import` that library. For instance, we will import the library allowing for manipulating arrays (vectors, matrices, etc.). This library is called `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use functions within the numpy library, like creating a 2 x 3 matrix with zeros inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = numpy.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise what `M` looks like, you can use the `print` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note tha the libray can be imported with a name (usually a shorter name), called a *namespace*. Namespaces make a code more readable and allow to define functions with a same name but within different namespaces. Numpy is usually imported as `np`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "M = np.zeros((2, 3))\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "\n",
    "Plotting data can be done using the `matplotlib` library (there are other ways to do, but this one is the most common and convenient as it uses matlab-like syntax). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try out this by plotting a simple vector of random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(M, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Try with a **higher number** of radomnly generated points... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn\n",
    "\n",
    "Sklearn (or scikit-learn) is one of the most used machine learning library in python. The library includes the most common classifiers: Support Vector Machine (SVM), k-Nearest Neighbour (kNN), Gaussian Mixture Models (GMM); the reduction dimension techniques, such as Principal Component Analysis (PCA), Independent Component Analysis (ICA); techniques to split datasets, to preprocess data and cross-validate models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test if sklearn is installed:\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn API**: http://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyexample\"></a>\n",
    "# Toy Example in Machine Learning: the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_description\"></a>\n",
    "## Dataset description\n",
    "\n",
    "This dataset consists of 3 different types of irises’ (**Setosa**, **Versicolour**, and **Virginica**) given by their:\n",
    "* Sepal Length\n",
    "* Sepal Width\n",
    "* Petal Length \n",
    "* Petal Width.\n",
    "\n",
    "<div style=\"width:300px; margin-top:10px; margin-right:10px; float:left;\">![pic1](https://apps.rhs.org.uk/plantselectorimages/detail/RHS_PUB0001482_1050.JPG \"pic1\") **Iris Setosa**</div>\n",
    "<div style=\"width:263px; margin-top:10px; margin-right:10px; float:left;\">![pic1](https://upload.wikimedia.org/wikipedia/commons/4/41/Iris_versicolor_3.jpg \"pic1\") **Iris Versicolour**</div>\n",
    "<div style=\"width:242px; margin-top:10px; margin-right:10px; float:left;\">![pic1](https://upload.wikimedia.org/wikipedia/commons/9/9f/Iris_virginica.jpg \"pic1\") **Iris Virginica**</div>\n",
    "<div style=\"clear: left;\"></div>\n",
    "\n",
    "The classes are encoded as integers: \n",
    "* Setosa = **0**\n",
    "* Versicolour = **1**\n",
    "* Virginica = **2**\n",
    "\n",
    "Rows are the samples and the columns the feature dimensions (Sepal Length, Sepal Width, Petal Length and Petal Width).\n",
    "```\n",
    "sample 1: [ 5.1,  3.5,  1.4,  0.2] \n",
    "sample 2: [ 4.9,  3. ,  1.4,  0.2] \n",
    "sample 3: [ 4.7,  3.2,  1.3,  0.2] \n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_visualising\"></a>\n",
    "## Visualizing the dataset\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "The iris dataset is included in the `sklearn` library as a benchmark for the algorithms implemented. The iris dataset is part of the `datasets` python classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object `iris` includes the data (4-dimensional data points) and the labels (integer associated to each datapoint within the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = iris.data\n",
    "labels = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of observations:', len(features), ' | Dimension:', len(features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 5 samples in the dataset\n",
    "features[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple statistics\n",
    "\n",
    "Before starting to train algorithms on a given dataset, it is good practice to \"visualise\" the dataset as much as you can. This has several benefits: better understanding the nature of the data, better understanding the complexity of the data, better scope the class of model would do a good job on these data, and better understanding model's results. \n",
    "\n",
    "When I write \"visualising\" a dataset, I mean having different metrics that can help these understandings. The simplest ones are computing the means and standard deviations of the data. This can be performed with `numpy` functions: `np.mean` for computing a mean over one axis of the data, and `np.std` to compute the standard deviation over one axis (the variance could also be considered using `np.var`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(features, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This give a **very** rough (and often insufficient) information about the dataset. The next step is to inspect the means and standard deviations of the data, computed per class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2]\n",
    "means = []\n",
    "stds = []\n",
    "for c in classes:\n",
    "    idx = np.where(labels == c)[0]\n",
    "    means.append(np.mean(features[idx, :], axis=0))\n",
    "    stds.append(np.std(features[idx, :], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,6))\n",
    "for c in classes:\n",
    "    plt.subplot(1,3,c+1)\n",
    "    plt.bar([0,1,2,3], means[c], yerr=stds[c])\n",
    "    plt.ylim([0., 7.])\n",
    "    plt.title('Class label ' + str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature dimension is **4**, which makes it hard to visualize in a simple 2-d plot. There are several ways to reduce the dimensions of a dataset. This procedure is simply called *dimension reduction*. I won't detail these techniques here, it is beyond the scope of this lecture. What we will do instead is to select manually two dimensions among the 4 in order to plot the data on a 2-d graph. \n",
    "\n",
    "We start by selecting the two first dimensions and visualize them in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = features[:,0] # sepal length\n",
    "data_y = features[:,1] # sepal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'Set1'\n",
    "cmap = matplotlib.cm.get_cmap('Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_x, data_y, c=cmap(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: graphs always need legends and axis labelling!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lecture4lib.utils import get_iris_data\n",
    "features_c0, _, _ = get_iris_data(classes=[0])\n",
    "features_c1, _, _ = get_iris_data(classes=[1])\n",
    "features_c2, _, _ = get_iris_data(classes=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = features_c0[:,0] # sepal length\n",
    "data_y = features_c0[:,1] # sepal width\n",
    "scatter(data_x, data_y, c=cmap(0), label='class 1')\n",
    "\n",
    "data_x = features_c1[:,0] # sepal length\n",
    "data_y = features_c1[:,1] # sepal width\n",
    "scatter(data_x, data_y, c=cmap(1), label='class 2')\n",
    "\n",
    "data_x = features_c2[:,0] # sepal length\n",
    "data_y = features_c2[:,1] # sepal width\n",
    "scatter(data_x, data_y, c=cmap(2), label='class 3')\n",
    "\n",
    "xlabel(\"Dimension 1: Sepal Length\")\n",
    "ylabel(\"Dimension 2: Sepal Width\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What can we say on the data based on this graph?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to visualise the dataset by selecting two other dimensions, for instance the 3rd and the 4th dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = features[:,2] # petal length\n",
    "data_y = features[:,3] # petal width\n",
    "scatter(data_x, data_y, c=cmap(labels))\n",
    "xlabel(\"Dimension 1: Petal Length\")\n",
    "ylabel(\"Dimension 2: Petal Width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_training\"></a>\n",
    "## Training a Classifier on the Dataset\n",
    "\n",
    "As use case, we will explore classifier training with the **Support Vector Machine (SVM)**. The support vector machine, in its simplest version, is a **linear discriminant model** which means that the technique tries to discriminate between classes using lieanr function (basically lines in 2D, planes in 3D, hyperplanes otherwise). \n",
    "\n",
    "Another way to say it is that the **decision boundaries** are linear. \n",
    "\n",
    "Useful readings (although a bit techncial) to know more about SVM:\n",
    "* C Cortes, V Vapnik. Support-vector networks. _Machine learning_ 20 (3), 273-297, 1995\n",
    "* B Schölkopf, AJ Smola. Learning with kernels: support vector machines, regularization, optimization, and beyond. *MIT press*, 2002\n",
    "\n",
    "SVM in sklearn can be imported simply using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new SVM instance called `classifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the linear version (simpler) of support vector machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a supervised learning task, meaning that it learns the function mapping feature samples to known labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in np.random.randint(len(labels), size=10):\n",
    "    print(features[n,:], '\\t==> ', labels[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(features, labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the two dimensions visualized previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = features[:,2] # petal length\n",
    "data_y = features[:,3] # petal width\n",
    "scatter(data_x, data_y, c=cmap(labels))\n",
    "\n",
    "classifier.fit(features[:,2:], labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES\n",
    "* `fit` is the generic function to train any methods in `sklearn`\n",
    "* for supervised methods, `fit` accepts two arguments: the feature data and their labels, that is `fit(X_train, y_train)`\n",
    "* for unsupervised methods, `fit` accepts only one argument: the feature data, that is `fit(X_train)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the 'training' in SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding training procedure in machine learning starts by understanding the **decision boundary** which is the set of borders delimiting regions in the feature space associated to each labels. Let's take the two last dimensions of the iris data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter(features[:,2], features[:,3], c=cmap(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider only two classes given by the <span style=\"color:#DD0000;\">**RED**</span> and <span style=\"color:#00DD00;\">**GREEN**</span> colours (class 0 and 1 respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data(classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features[:, 2:]\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: what is the best decision boundary between classes 0 and 1?**\n",
    "\n",
    "Linear models, such as SVM, consider linear decision boundaries. In a 2-dimensional space, a linear decision boundary is a **line**. A line can be defined by 2 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope = -0.1\n",
    "intercept = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the corresponding line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1,5)\n",
    "boundary_y = slope * boundary_x + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], color=colors)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Is that good enough?**\n",
    "\n",
    "Let's imagine that we have a new point coming in with data `(3.5, 0.7)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=colors)\n",
    "plot(boundary_x, boundary_y, '-k')\n",
    "scatter(3.5, 0.7, c='black', s=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think? Which class does the blue point belong to? \n",
    "\n",
    "Let's try other values for the slope and the intercept..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope = -1.0\n",
    "intercept = 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1,4)\n",
    "boundary_y = slope * boundary_x + intercept\n",
    "\n",
    "scatter(X_train[:,0], X_train[:,1], c=colors)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Looks better...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About **training**:\n",
    "* means finding the best parameters wrt the set of samples\n",
    "* can often be understood as an OPTIMIZATION problem (i.e. finding a decision boundary such as miminzing a certain **cost function**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_testing\"></a>\n",
    "## Testing a Classifier on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a classifier is to inspect if the classifier performs a good prediction (estimated the label/class) on data that are not included in the dataset used to train it. The idea is to test the *generalizability* of the trained algorithm. Alrotihms can then be compared based on their prediction capabilities. Prediction capability is usually reported as accuracy percentage: what is the percentage of the testing dataset that has been correctly classified (predicted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test a classifie, we then need to split the whole dataset into a training dataset on which the classifier will be trained and a testing dataset on which we will test the prediciton capabilities. There are different ways to split a dataset. Sklearn has several methods for that (see [API](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)):\n",
    "\n",
    "Function | Description\n",
    "--- | ---\n",
    "`model_selection.KFold([n_splits, shuffle, ...])` | K-Folds cross-validator\n",
    "`model_selection.GroupKFold([n_splits])`\t| K-fold iterator variant with non-overlapping groups.\n",
    "`model_selection.StratifiedKFold([n_splits, ...])`\t| Stratified K-Folds cross-validator\n",
    "`model_selection.LeaveOneGroupOut()`\t| Leave One Group Out cross-validator\n",
    "`model_selection.LeavePGroupsOut(n_groups)`\t| Leave P Group(s) Out cross-validator\n",
    "`model_selection.LeaveOneOut()`\t| Leave-One-Out cross-validator\n",
    "`model_selection.LeavePOut(p)`\t| Leave-P-Out cross-validator\n",
    "`model_selection.ShuffleSplit([n_splits, ...])`\t| Random permutation cross-validator\n",
    "`model_selection.GroupShuffleSplit([...])`\t| Shuffle-Group(s)-Out cross-validation iterator\n",
    "`model_selection.StratifiedShuffleSplit([...])`\t| Stratified ShuffleSplit cross-validator\n",
    "`model_selection.PredefinedSplit(test_fold)`\t| Predefined split cross-validator\n",
    "`model_selection.TimeSeriesSplit([n_splits])`\t| Time Series cross-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partition of the initial dataset is usually caleld a fold. In our example below, we will used the **stratified k-fold** which creates folds preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's for instance declare a stratified spitting method with a number of splits equals to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold( n_splits=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the two dimensions plotted previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array( features[:,:2] )\n",
    "y = np.array( labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in splitter.split(X,y):\n",
    "    print(\"training:\", labels[train_index])\n",
    "    print(\"testing:\", labels[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SVM on the splitted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index, test_index = next(splitter.split(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = X[train_index]\n",
    "y_train = y[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing dataset\n",
    "X_test = X[test_index]\n",
    "y_test = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init SVM classifier\n",
    "classifier = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train VM classifier\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test SVM classifier and store output\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of errors of our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_errors = 0\n",
    "for i,yi in enumerate(y_pred):\n",
    "    if (yi != y_test[i]):\n",
    "        num_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( 1.0 - num_errors/len(y_pred) ) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the classification accuracy in percentage on the current set of training/testing datasets. For the sake of comparison, the **worst classifier** would have returned 20% (_chance level_). In sklearn we can directly compute the score with the `score()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn function\n",
    "score = classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT** we test only on one split, what if the split leads to particularly well disciminated training dataset but not testing dataset. Or the contrary... The idea is to consider more than one split, to compute the score on each split and then compute the average (and the variance of the scores) which gives a more robust way (statistically) to assess a classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test  = X[test_index]\n",
    "    y_test  = y[test_index]   \n",
    "    \n",
    "    # declare classifier\n",
    "    classifier = svm.SVC(kernel='linear')\n",
    "    classifier.fit(X_train,y_train)   \n",
    "    \n",
    "    # compute score on testing dataset and store it\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    all_scores.append(score)  \n",
    "    \n",
    "    # print score\n",
    "    print('score: %.2f%%'%(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(all_scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(all_scores)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of evaluating a model on various splits within a bigger dataset is called **cross-validation**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_boundaries\"></a>\n",
    "## Assessing Training: Decision Boundaries\n",
    "\n",
    "For the sake of comparison with our manual exploration before, we will now train the SVM classifier with the same data, that is to say the dataset comprising only the 2 first classes (Setosa, Versicolour), and considering only the last two dimensions of the data (Petal Length and Petal Width):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data(classes=[0,1])\n",
    "X_train = features[:, 2:]\n",
    "y_train = labels\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising linear boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sklearn framewor, results from training the SVM are given by the the `coef_` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = classifier.coef_[0]\n",
    "slope = -coefs[0] / coefs[1]\n",
    "intercept = classifier.intercept_[0] / coefs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1.5,3.5)\n",
    "boundary_y = slope * boundary_x - intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=colors)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising boundaries as regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_x = np.linspace(0.75, 5.3, 300)\n",
    "mesh_y = np.linspace(-0.8, 2.5, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good... Let's see more complex decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data(classes=[0,1])\n",
    "X_train = features[:, 2:]\n",
    "y_train = labels\n",
    "classifier = svm.SVC(kernel='rbf')\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)\n",
    "        \n",
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_multiclass\"></a>\n",
    "## Binary vs. Multiclass Problem\n",
    "\n",
    "Until now we have only seen the special case of discriminating between two classes: 0 or 1. But most of the real-world problems are actually dealing with multiple classes. For instance, in self-driving car, the car needs to discriminate between a human crossing the street, a dog crossing the street, a sign, another car, a truck, a bike, etc... The number of classes can be very high. \n",
    "\n",
    "Here, within our toy example, we will simply add the left-aside class and examine how it affects the decision boundarues as visualised before. Note that we are still using the two last dimensions of the data for the sake of understanding and visualisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data(classes=[0, 1, 2])\n",
    "X_train = features[:, 2:]\n",
    "y_train = labels\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with more than one class, SVM finds decision boundaries between pair of classes:\n",
    "* Class 1 vs. Class 2\n",
    "* Class 1 vs. Class 3\n",
    "* Class 2 vs. Class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_x = np.linspace(0.75, 7.1, 200)\n",
    "mesh_y = np.linspace(-0.8, 2.7, 200)\n",
    "\n",
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)\n",
    "        \n",
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='rbf')\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)\n",
    "        \n",
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"gr\"></a>\n",
    "# Gesture Recognition\n",
    "\n",
    "When we talk about gestures, we could understand two types of gestures (see [Lecture 2 - Gestural interaction](https://github.com/bcaramiaux/GMI/blob/master/course-slides/Lecture2-Gestural-Interaction.pdf)): a posture or a temporal gesture. \n",
    "\n",
    "A posture is a static gesture such as:\n",
    "<div style=\"width:200px;\">![gesture](http://blog.clubcarlson.com/wp-content/uploads/2014/04/shutterstock_96934004-1024x731.jpg)</div>\n",
    "\n",
    "A gesture is temporal meaning that it involves a trajectory in a the physical space:\n",
    "<div style=\"width:200px;\">![gesture](http://www.samsung.com/ph/smarttv/common/guide_book_3p_si/img/hand1.png)</div>\n",
    "\n",
    "In the following we consider the dataset from the dollar1-recognizer (which are temporal gestures):\n",
    "<div style=\"width:300px; margin: 0 auto;\">![onedol](http://depts.washington.edu/madlab/proj/dollar/unistrokes.gif)</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lecture4lib.utils import load_one_dollar_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = load_one_dollar_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of gestures per class is **300**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"gr_visualising\"></a>\n",
    "## Visualising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gesture = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset, labels = load_one_dollar_ds(gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in dataset:\n",
    "    plot(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in dataset:\n",
    "    plot(g[:,0], g[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Lecture4lib.utils import mean_gesture, std_gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = mean_gesture(gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(g[:,0], g[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_g = mean_gesture(gesture)\n",
    "std_g = std_gesture(gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mean_g[:,0], mean_g[:,1], '-k')\n",
    "plot(mean_g[:,0] + std_g[:,0], mean_g[:,1] + std_g[:,1], '--b')\n",
    "plot(mean_g[:,0] - std_g[:,0], mean_g[:,1] - std_g[:,1], '--b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,16))\n",
    "for k in range(0,16):\n",
    "    mean_g = mean_gesture(k)\n",
    "    std_g = std_gesture(k)\n",
    "    subplot(4,4,k+1)\n",
    "    plot(mean_g[:,0], mean_g[:,1], '-k')\n",
    "    plot(mean_g[:,0] + std_g[:,0], mean_g[:,1] + std_g[:,1], '--b')\n",
    "    plot(mean_g[:,0] - std_g[:,0], mean_g[:,1] - std_g[:,1], '--b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"gr_training_testing\"></a>\n",
    "## Training and Testing\n",
    "\n",
    "Let's get the gesture data such as all of them have the same size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset, labels = load_one_dollar_ds(resample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 50, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = np.resize(dataset, (4800, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score with SVM: 99.33%\n",
      "  standard deviation: 0.34%\n"
     ]
    }
   ],
   "source": [
    "classifier = svm.SVC(kernel='linear');\n",
    "\n",
    "num_tests = 12\n",
    "splitter = StratifiedKFold(n_splits = num_tests)\n",
    "all_scores = []\n",
    "\n",
    "for train_index, test_index in splitter.split(dataset, labels):\n",
    "    X_train, y_train, X_test, y_test = dataset[train_index], labels[train_index], dataset[test_index], labels[test_index]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    all_scores.append(score)\n",
    "\n",
    "print('Mean score with SVM: {:.2f}%'.format(np.mean(all_scores)*100.0))\n",
    "print('  standard deviation: {:.2f}%'.format(np.std(all_scores)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we usually compare various models in order to pick the best one for a particular application. Model comparison can be done through cross-validation.\n",
    "\n",
    "For the sake of comparison, we compare classification accuracy for two classifiers:\n",
    "* **Linear SVM**\n",
    "    *  `svm.SVC(kernel='linear')`\n",
    "* **k-Nearest Neighbour**\n",
    "    * `neighbors.KNeighborsClassifier()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is kNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN assigns a label to a new input vector from a majority vote of its k nearest neighbors:\n",
    "\n",
    "![kNN](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png \"kNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', \n",
    "               'kNN']\n",
    "all_scores = {'SVM-linear': [], \n",
    "              'kNN': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "        # print score\n",
    "        print(clf, 'score: %.2f%%'%(score*100)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    print(clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric vs. Non-Parametric approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric**\n",
    "* Characterization:\n",
    "    * Learning a finite number of parameters\n",
    "    * The complexity does not depend on the size of the dataset\n",
    "* Examples\n",
    "    * **linear SVM**: $N = (D + 1) \\times C$\n",
    "    * mulitlayer perceptron: $N = D + C + \\sum_{k=1}^{L-1} N^{(k)}\\times N^{(k+1)}$\n",
    "\n",
    "**Non-parametric**\n",
    "* Characterization\n",
    "    * Complexity depends on the size of the dataset\n",
    "    * Number of parameters can be _infinite_\n",
    "* Examples\n",
    "    * **k-Nearest Neighbors**\n",
    "    * Nonlinear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> **Non-parametric doesn't mean that the method has no parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_by_nn = []\n",
    "for num_neighbors in range(1,50):\n",
    "    classifier = neighbors.KNeighborsClassifier(num_neighbors)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score_by_nn.append( classifier.score(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(12,6))\n",
    "plot(range(1,50), score_by_nn)\n",
    "xlabel('Number of Neighbors')\n",
    "ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_by_nn_train = []\n",
    "score_by_nn_test = []\n",
    "for num_neighbors in range(1,50):\n",
    "    classifier = neighbors.KNeighborsClassifier(num_neighbors)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score_by_nn_train.append( classifier.score(X_train, y_train) )\n",
    "    score_by_nn_test.append( classifier.score(X_test, y_test) )\n",
    "figure(figsize=(12,6))\n",
    "plot(range(1,50), score_by_nn_train, label=\"Training\")\n",
    "plot(range(1,50), score_by_nn_test, label=\"Testing\")\n",
    "legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "xlabel('Number of Neighbors')\n",
    "ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing classifiers on the original vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array( features )\n",
    "y = np.array( labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', \n",
    "               'SVM-nonlinear', \n",
    "               'kNN']\n",
    "all_scores = {'SVM-linear': [], \n",
    "              'SVM-nonlinear': [], \n",
    "              'kNN': []}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='SVM-nonlinear'):\n",
    "            classifier = svm.SVC(kernel='rbf')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "        # print score\n",
    "        print(clf, 'score: %.2f%%'%(score*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    print('-', clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "* Classification accuracies are better than in the case of 2-dimensions\n",
    "* kNN and SVM linear are returning ~ the same results\n",
    "* Non-linear SVM returns classification accuracy at **chance level** (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some techniques are sensitive to the input vectors range, such as non linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', 'SVM-nonlinear', 'kNN']\n",
    "all_scores = {'SVM-linear': [], 'SVM-nonlinear': [], 'kNN': []}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# preprocessing: center and scale\n",
    "X = np.subtract( X, np.mean(X, axis=0) )\n",
    "X = np.divide( X, np.std(X, axis=0) )\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='SVM-nonlinear'):\n",
    "            classifier = svm.SVC(kernel='rbf')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "for clf in classifiers:\n",
    "    print('-', clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "* Sklearn has several functions to pre-process data before feeding them to some classifiers or regressors\n",
    "* More: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful step is to reduce dimensions of the input vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "for c in classes:\n",
    "    for e in excerpts:\n",
    "        data = np.loadtxt('datasets/features/%s_%03i.mfcc'%(c,e), delimiter=',')\n",
    "        for d_vect in data:\n",
    "            features.append(list(d_vect))\n",
    "X = np.array( features )\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "#scaler = preprocessing.StandardScaler().fit(X)\n",
    "#X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter(X[:,0], X[:,1], c=label_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', 'SVM-nonlinear', 'kNN']\n",
    "all_scores = {'SVM-linear': [], 'SVM-nonlinear': [], 'kNN': []}\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='SVM-nonlinear'):\n",
    "            classifier = svm.SVC(kernel='rbf')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "for clf in classifiers:\n",
    "    print('-', clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_proj = pca.transform(X)\n",
    "scatter(X_proj[:,0], X_proj[:,1], c=label_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_proj = X_proj[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', 'SVM-nonlinear', 'kNN']\n",
    "all_scores = {'SVM-linear': [], 'SVM-nonlinear': [], 'kNN': []}\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in splitter.split(X_proj,y):\n",
    "    # select training and testing datasets\n",
    "    X_train = X_proj[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X_proj[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='SVM-nonlinear'):\n",
    "            classifier = svm.SVC(kernel='rbf')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "for clf in classifiers:\n",
    "    print('-', clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for pc in range(2,48):\n",
    "    \n",
    "    X_proj = pca.transform(X)[:,:pc]\n",
    "\n",
    "    score_test = []\n",
    "    for train_index, test_index in splitter.split(X_proj,y):\n",
    "        X_train, X_test = X_proj[train_index], X_proj[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        classifier = neighbors.KNeighborsClassifier()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        score_test.append( classifier.score(X_test,y_test) )  \n",
    "    scores.append(np.mean(score_test))\n",
    "\n",
    "figure(figsize=(10,6))\n",
    "plot(scores)\n",
    "xlabel(\"Number of components\")\n",
    "ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "kpca = FastICA()\n",
    "kpca.fit(X)\n",
    "X_proj = kpca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for pc in range(2,48):\n",
    "    \n",
    "    X_proj = kpca.transform(X)[:,:pc]\n",
    "\n",
    "    score_test = []\n",
    "    for train_index, test_index in splitter.split(X_proj,y):\n",
    "        X_train, X_test = X_proj[train_index], X_proj[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        classifier = neighbors.KNeighborsClassifier()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        score_test.append( classifier.score(X_test,y_test) )  \n",
    "    scores.append(np.mean(score_test))\n",
    "\n",
    "figure(figsize=(10,6))\n",
    "plot(scores)\n",
    "xlabel(\"Number of components\")\n",
    "ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "About this material: copyright Baptiste Caramiaux (write me for any questions or use of this material [email](mailto:baptiste.caramiaux@ircam.fr))\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
