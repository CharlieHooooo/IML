{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 - Machine Learning for Gesture Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<!-- MarkdownTOC autolink=true autoanchor=true bracket=round -->\n",
    "\n",
    "- [Machine Learning](#machinelearning)\n",
    "    - [Types of Learning](#ml_types)\n",
    "    - [Phases](#ml_phases)\n",
    "    - [Machine learning in python](#ml_python)\n",
    "- [Toy Example in Machine Learning: the Iris Dataset](#toyexample)\n",
    "    - [Dataset description](#toyex_description)\n",
    "    - [Visualising Dataset](#toyex_visualising)\n",
    "    - [Training a Classifier on the Dataset](#toyex_training)\n",
    "    - [Testing a Classifier on the Dataset](#toyex_testing)\n",
    "    - [Assessing Training: Decision Boundaries](#toyex_boundaries)\n",
    "    - [Binary vs. Multiclass Problem](#toyex_multiclass)\n",
    "- [Gesture Recognition](#gr)\n",
    "    - [Visualising Dataset](#gr_visualising)\n",
    "    - [Training and Testing](#gr_training_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"machinelearning\"></a>\n",
    "# Machine Learning\n",
    "\n",
    "Machine learning has become recently a hot topic present in scientific literature as well as in the general public literature. Roughly saying, machine learning is *way* for computer to learn from data, and consequently, has been  at the heart of artificial intelligence algorithms. ML is nowadays already in many of the products we use Today from recommendation systems able to provide personnalized recommendations for filems (Netflix), music (Apple Music) or more general products (Amazon). Machine learning is also widely used to filters our spam, to recognise voice in personnal assistants, etc. \n",
    "\n",
    "A formal definition of **machine learning** (ML) can be: a set of methods that can **automatically detect patterns** in data, and then use the uncovered patterns to **predict future data** (*from Machine Learning: A Probabilistic Perspective (Murphy 2012)*)\n",
    "\n",
    "<a name=\"ml_types\"></a>\n",
    "## Types of learning\n",
    "\n",
    "What are the types of \"learning\"? In ML literature, there are several types of learning, the three main types are: supervised learning, unsupervised learning and reinforcement learning. \n",
    "\n",
    "In supervised learning, you have access to a dataset where each datapoint, considered as an *input*, has an associated known output, that can be discrete (like a *label*) or continuous. The goal of a supervised learning algorithm is to learn the relationship between the inputs and their associated outputs. In case the outputs are discrete (*labels*) we call the task **classification**, in case the outputs are continous, the task is called **regression**. \n",
    "\n",
    "In unsupervised learning, you have acess to a dataset where there are only *inputs* (datapoints without associated labels or some values). The goal of an unsupervised learning algorithm is then to infer from these data the underlying structure. This task is usually harder than supervised learning. \n",
    "\n",
    "Reinforcement learning is a different paradigm: the learning occurs through interaction with the environment. In reinforcement learning, an agent takes actions in an environment such as to maximize some cumulative rewards. Each action taken produces a reward that the agent takes into account in order to assess the \"quality\" of the action. \n",
    "\n",
    "\n",
    "<a name=\"ml_phases\"></a>\n",
    "## Phases\n",
    "\n",
    "In ML, we usually consider two phases: **learning** then **testing**. **Training** an algorithm in machine learning means detecting patterns in a dataset. **Testing** an algorithm means predicting future data, that is generalizing the uncovered trained patterns to new datasets\n",
    "\n",
    "<a name=\"ml_python\"></a>\n",
    "## Machine Learning in Python\n",
    "\n",
    "At this stage of the course, you should have installed Python 3, Jupyter Notebook and all the useful lirbaries used in this course (like sklearn). If not, please refer to the README.md \n",
    "\n",
    "### Quick introduction to jupyter notebook\n",
    "\n",
    "#### Cell\n",
    "Cell in jupyter notebook is where we write code or text that can be executed (or interpreted). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries \n",
    "\n",
    "At this stage, you cannot do much except calling the basic python functions such as '+' or '-' (and others). To be able to use additional functions we use libraries. Libraries are collections of functions that can be called in python programs. In order to use the functions included in a library, you first have to `import` that library. For instance, we will import the library allowing for manipulating arrays (vectors, matrices, etc.). This library is called `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use functions within the numpy library, like creating a 2 x 3 matrix with zeros inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = numpy.zeros((7, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise what `M` looks like, you can use the `print` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the libray can be imported with a name (usually a shorter name), called a *namespace*. Namespaces make a code more readable and allow to define functions with a same name but within different namespaces. Numpy is usually imported as `np`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "M = np.zeros((5, 4))\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data\n",
    "\n",
    "Plotting data can be done using the `matplotlib` library (there are other ways to do, but this one is the most common and convenient as it uses matlab-like syntax). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try out this by plotting a simple vector of random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.random.randn(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we plotted the points sequentially, sometimes it is useful to display their **distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE** \n",
    "\n",
    "Try with a **higher number** of radomnly generated points.\n",
    "\n",
    "What is this shape? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(M, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn\n",
    "\n",
    "Sklearn (or scikit-learn) is one of the most used machine learning library in python. The library includes the most common classifiers: Support Vector Machine (SVM), k-Nearest Neighbour (kNN), Gaussian Mixture Models (GMM); the reduction dimension techniques, such as Principal Component Analysis (PCA), Independent Component Analysis (ICA); techniques to split datasets, to preprocess data and cross-validate models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if sklearn is installed:\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn API**: http://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning:\n",
    "- Tensorflow (google)\n",
    "- Keras (google)\n",
    "- PyTorch\n",
    "- Caffe\n",
    "- ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyexample\"></a>\n",
    "# Toy Example in Machine Learning: the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_description\"></a>\n",
    "## Dataset Description\n",
    "\n",
    "This dataset consists of 3 different types of irisesâ€™ (**Setosa**, **Versicolour**, and **Virginica**) given by their:\n",
    "* Sepal Length\n",
    "* Sepal Width\n",
    "* Petal Length \n",
    "* Petal Width.\n",
    "\n",
    "<div style=\"width:300px; margin-top:10px; margin-right:10px; float:left;\">![pic1](https://apps.rhs.org.uk/plantselectorimages/detail/RHS_PUB0001482_1050.JPG \"pic1\") **Iris Setosa**</div>\n",
    "<div style=\"width:263px; margin-top:10px; margin-right:10px; float:left;\">![pic1](https://upload.wikimedia.org/wikipedia/commons/4/41/Iris_versicolor_3.jpg \"pic1\") **Iris Versicolour**</div>\n",
    "<div style=\"width:242px; margin-top:10px; margin-right:10px; float:left;\">![pic1](https://upload.wikimedia.org/wikipedia/commons/9/9f/Iris_virginica.jpg \"pic1\") **Iris Virginica**</div>\n",
    "<div style=\"clear: left;\"></div>\n",
    "\n",
    "The classes are encoded as integers: \n",
    "* Setosa = **0**\n",
    "* Versicolour = **1**\n",
    "* Virginica = **2**\n",
    "\n",
    "Rows are the samples and the columns the feature dimensions (Sepal Length, Sepal Width, Petal Length and Petal Width).\n",
    "```\n",
    "sample 1: [ 5.1,  3.5,  1.4,  0.2] \n",
    "sample 2: [ 4.9,  3. ,  1.4,  0.2] \n",
    "sample 3: [ 4.7,  3.2,  1.3,  0.2] \n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_visualising\"></a>\n",
    "## Visualizing the dataset\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "The iris dataset is included in the `sklearn` library as a benchmark for the algorithms implemented. The iris dataset is part of the `datasets` python classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object `iris` includes the data (4-dimensional data points) and the labels (integer associated to each datapoint within the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris.data\n",
    "labels = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of observations:', len(features), ' | Dimension:', len(features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 5 samples in the dataset\n",
    "features[0:5,0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple statistics\n",
    "\n",
    "Before starting to train algorithms on a given dataset, it is good practice to \"visualise\" the dataset as much as you can. \n",
    "\n",
    "This has several benefits: \n",
    "- to better understand the nature of the data, \n",
    "- to better understand the complexity of the data, \n",
    "- to better scope the class of model would do a good job on these data, \n",
    "- and to better understand model's results. \n",
    "\n",
    "By \"visualising\" a dataset, I mean having different metrics that can help these understandings. The simplest way is through simple statistics: computing the means and standard deviations of the data. \n",
    "\n",
    "In Python, this can be computed with `numpy` functions: `np.mean` for computing a mean over one axis of the data, and `np.std` to compute the standard deviation over one axis (the variance could also be considered using `np.var`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2.1+3.2+4.3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(features, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This give a **very** rough and insufficient information about the dataset. \n",
    "\n",
    "The next step is to inspect the means and standard deviations of the data, computed per class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2]\n",
    "means = []\n",
    "stds = []\n",
    "for c in classes:\n",
    "    idx = np.where(labels == c)[0]\n",
    "    means.append(np.mean(features[idx, :], axis=0))\n",
    "    stds.append(np.std(features[idx, :], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,6))\n",
    "for c in classes:\n",
    "    plt.subplot(1,3,c+1)\n",
    "    plt.bar([0,1,2,3], means[c], yerr=stds[c])\n",
    "    plt.ylim([0., 7.])\n",
    "    plt.title('Class label ' + str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature dimension is **4**, which makes it hard to visualize in a simple 2-d plot. There are several ways to reduce the dimensions of a dataset. This procedure is simply called *dimension reduction*. I won't detail these techniques here, it is beyond the scope of this lecture. What we will do instead is to select manually two dimensions among the 4 in order to plot the data on a 2-d graph. \n",
    "\n",
    "We start by selecting the two first dimensions and visualize them in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = features[:,0] # sepal length\n",
    "data_y = features[:,1] # sepal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'Set1'\n",
    "cmap = matplotlib.cm.get_cmap('Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_x, data_y, c=cmap(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: graphs always need legends and axis labelling!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lecture4lib.utils import get_iris_data\n",
    "features_c0, _, _ = get_iris_data(classes=[0])\n",
    "features_c1, _, _ = get_iris_data(classes=[1])\n",
    "features_c2, _, _ = get_iris_data(classes=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = features_c0[:,0] # sepal length\n",
    "data_y = features_c0[:,1] # sepal width\n",
    "scatter(data_x, data_y, c=cmap(0), label='class 1')\n",
    "\n",
    "data_x = features_c1[:,0] # sepal length\n",
    "data_y = features_c1[:,1] # sepal width\n",
    "scatter(data_x, data_y, c=cmap(1), label='class 2')\n",
    "\n",
    "data_x = features_c2[:,0] # sepal length\n",
    "data_y = features_c2[:,1] # sepal width\n",
    "scatter(data_x, data_y, c=cmap(2), label='class 3')\n",
    "\n",
    "xlabel(\"Dimension 1: Sepal Length\")\n",
    "ylabel(\"Dimension 2: Sepal Width\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What can we say on the data based on this graph?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE**\n",
    "\n",
    "Visualise other dimensions of the dataset. Try to find the best visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring by hand may be good to understand the data but it is too tedious to find the best criteria highlighting patterns in the data. That's why **Machine Learning** exists: finding underlying patterns and being able to generalise, that is make prediction, based on these patterns, on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_training\"></a>\n",
    "## Training a Classifier on the Dataset\n",
    "\n",
    "As use case, we will explore classifier training with the **Support Vector Machine (SVM)**. The support vector machine, in its simplest version, is a **linear discriminant model** which means that the technique tries to discriminate between classes using lieanr function (basically lines in 2D, planes in 3D, hyperplanes otherwise). \n",
    "\n",
    "Another way to say it is that the **decision boundaries** are linear. \n",
    "\n",
    "Useful readings (although a bit techncial) to know more about SVM:\n",
    "* C Cortes, V Vapnik. Support-vector networks. _Machine learning_ 20 (3), 273-297, 1995\n",
    "* B SchÃ¶lkopf, AJ Smola. Learning with kernels: support vector machines, regularization, optimization, and beyond. *MIT press*, 2002\n",
    "\n",
    "SVM in sklearn can be imported simply using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new SVM instance called `classifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the linear version (simpler) of support vector machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a supervised learning task, meaning that it learns the function mapping feature samples to known labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in np.random.randint(len(labels), size=10):\n",
    "    print(features[n,:], '\\t==> ', labels[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(features, labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the two dimensions visualized previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = features[:,2] # petal length\n",
    "data_y = features[:,3] # petal width\n",
    "scatter(data_x, data_y, c=cmap(labels))\n",
    "\n",
    "classifier.fit(features[:,2:], labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES\n",
    "* `fit` is the generic function to train any methods in `sklearn`\n",
    "* for supervised methods, `fit` accepts two arguments: the feature data and their labels, that is `fit(X_train, y_train)`\n",
    "* for unsupervised methods, `fit` accepts only one argument: the feature data, that is `fit(X_train)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the 'training' in SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding training procedure in machine learning starts by understanding the **decision boundary** which is the set of borders delimiting regions in the feature space associated to each labels. Let's take the two last dimensions of the iris data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter(features[:,2], features[:,3], c=cmap(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider only two classes given by the <span style=\"color:#DD0000;\">**RED**</span> and <span style=\"color:#0000DD;\">**BLUE**</span> colours (class 0 and 1 respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data(classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features[:, 2:]\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: what is the best decision boundary between classes 0 and 1?**\n",
    "\n",
    "Linear models, such as SVM, consider linear decision boundaries. In a 2-dimensional space, a linear decision boundary is a **line**. A line can be defined by 2 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = -0.1\n",
    "intercept = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the corresponding line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1,5)\n",
    "boundary_y = slope * boundary_x + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], color=colors)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Is that good enough?**\n",
    "\n",
    "Let's imagine that we have a new point coming in with data `(3.5, 0.7)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=colors)\n",
    "plot(boundary_x, boundary_y, '-k')\n",
    "scatter(3.5, 0.7, c='black', s=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think? Which class does the blue point belong to? \n",
    "\n",
    "Let's try other values for the slope and the intercept..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = -1.0\n",
    "intercept = 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1,4)\n",
    "boundary_y = slope * boundary_x + intercept\n",
    "\n",
    "scatter(X_train[:,0], X_train[:,1], c=colors)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Looks better...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About **training**:\n",
    "* means finding the best parameters wrt the set of samples\n",
    "* can often be understood as an OPTIMIZATION problem (i.e. finding a decision boundary such as miminzing a certain **cost function**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(features[:,2:], labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = classifier.coef_[0]\n",
    "slope = -coefs[0] / coefs[1]\n",
    "intercept = classifier.intercept_[0] / coefs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1.5,3.5)\n",
    "boundary_y = slope * boundary_x - intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=colors)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising boundaries as regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_x = np.linspace(0.75, 5.3, 300)\n",
    "mesh_y = np.linspace(-0.8, 2.5, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good... Let's see more complex decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data(classes=[0,1])\n",
    "X_train = features[:, 2:]\n",
    "y_train = labels\n",
    "classifier = svm.SVC(kernel='rbf')\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)\n",
    "        \n",
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_testing\"></a>\n",
    "## Testing a Classifier on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a classifier is to inspect if the classifier performs a good prediction (estimated the label/class) on data that are not included in the dataset used to train it. The idea is to test the *generalizability* of the trained algorithm. \n",
    "\n",
    "Algorithms can then be compared based on their prediction capabilities. Prediction capability is usually reported as accuracy percentage: what is the percentage of the testing dataset that has been correctly classified (predicted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test a classifier, we then need to split the whole dataset into a training dataset on which the classifier will be trained and a testing dataset on which we will test the prediciton capabilities. There are different ways to split a dataset. Sklearn has several methods for that (see [API](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)):\n",
    "\n",
    "Function | Description\n",
    "--- | ---\n",
    "`model_selection.KFold([n_splits, shuffle, ...])` | K-Folds cross-validator\n",
    "`model_selection.GroupKFold([n_splits])`\t| K-fold iterator variant with non-overlapping groups.\n",
    "`model_selection.StratifiedKFold([n_splits, ...])`\t| Stratified K-Folds cross-validator\n",
    "`model_selection.LeaveOneGroupOut()`\t| Leave One Group Out cross-validator\n",
    "`model_selection.LeavePGroupsOut(n_groups)`\t| Leave P Group(s) Out cross-validator\n",
    "`model_selection.LeaveOneOut()`\t| Leave-One-Out cross-validator\n",
    "`model_selection.LeavePOut(p)`\t| Leave-P-Out cross-validator\n",
    "`model_selection.ShuffleSplit([n_splits, ...])`\t| Random permutation cross-validator\n",
    "`model_selection.GroupShuffleSplit([...])`\t| Shuffle-Group(s)-Out cross-validation iterator\n",
    "`model_selection.StratifiedShuffleSplit([...])`\t| Stratified ShuffleSplit cross-validator\n",
    "`model_selection.PredefinedSplit(test_fold)`\t| Predefined split cross-validator\n",
    "`model_selection.TimeSeriesSplit([n_splits])`\t| Time Series cross-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partition of the initial dataset is usually caleld a fold. In our example below, we will used the **stratified k-fold** which creates folds preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's for instance declare a stratified spitting method with a number of splits equals to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold( n_splits = 3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the two dimensions plotted previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, _ = get_iris_data(classes=[0,1])\n",
    "\n",
    "X = np.array( features[:,:2] )\n",
    "y = np.array( labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in splitter.split(X,y):\n",
    "    print(\"training:\", labels[train_index])\n",
    "    print(\"testing:\", labels[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = next(splitter.split(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = X[train_index]\n",
    "y_train = y[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing dataset\n",
    "X_test = X[test_index]\n",
    "y_test = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init SVM classifier\n",
    "classifier = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train VM classifier\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test SVM classifier and store output\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of errors of our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_errors = 0\n",
    "for i,yi in enumerate(y_pred):\n",
    "    if (yi != y_test[i]):\n",
    "        num_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( 1.0 - num_errors/len(y_pred) ) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the classification accuracy in percentage on the current set of training/testing datasets. \n",
    "\n",
    "The **worst classifier** would have returned 50% (_chance level_). In sklearn we can directly compute the score with the `score()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn function\n",
    "score = classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT** we test only on one split, what if the split leads to particularly well disciminated training dataset but not testing dataset. Or the contrary... The idea is to consider more than one split, to compute the score on each split and then compute the average (and the variance of the scores) which gives a more robust way (statistically) to assess a classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test  = X[test_index]\n",
    "    y_test  = y[test_index]   \n",
    "    \n",
    "    # declare classifier\n",
    "    classifier = svm.SVC(kernel='linear')\n",
    "    classifier.fit(X_train,y_train)   \n",
    "    \n",
    "    # compute score on testing dataset and store it\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    all_scores.append(score)  \n",
    "    \n",
    "    # print score\n",
    "    print('score: %.2f%%'%(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(all_scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(all_scores)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of evaluating a model on various splits within a bigger dataset is called **cross-validation**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toyex_multiclass\"></a>\n",
    "### Application to Multiclass Problem\n",
    "\n",
    "Until now we have only seen the special case of discriminating between two classes: 0 or 1. But most of the real-world problems are actually dealing with multiple classes. For instance, in self-driving car, the car needs to discriminate between a human crossing the street, a dog crossing the street, a sign, another car, a truck, a bike, etc... The number of classes can be very high. \n",
    "\n",
    "Here, within our toy example, we will simply add the left-aside class and examine how it affects the decision boundarues as visualised before. Note that we are still using the two last dimensions of the data for the sake of understanding and visualisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data(classes=[0, 1, 2])\n",
    "X_train = features[:, 2:]\n",
    "y_train = labels\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with more than one class, SVM finds decision boundaries between pair of classes:\n",
    "* Class 1 vs. Class 2\n",
    "* Class 1 vs. Class 3\n",
    "* Class 2 vs. Class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the SVM classifier on the whole dataset, that is to say considering all the features and all the classes, cross-validating across 10 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, colors = get_iris_data()\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test  = X[test_index]\n",
    "    y_test  = y[test_index]   \n",
    "    \n",
    "    # declare classifier\n",
    "    classifier = svm.SVC(kernel='linear')\n",
    "    classifier.fit(X_train,y_train)   \n",
    "    \n",
    "    # compute score on testing dataset and store it\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    all_scores.append(score)  \n",
    "    \n",
    "    # print score\n",
    "    print('score: %.2f%%'%(score*100))\n",
    "\n",
    "print('\\nMean accuracy={:.2f}% (Std={:.2f}%)'.format(np.mean(all_scores)*100, np.std(all_scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_x = np.linspace(0.75, 7.1, 200)\n",
    "mesh_y = np.linspace(-0.8, 2.7, 200)\n",
    "\n",
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)\n",
    "        \n",
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='rbf')\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_area = np.zeros((len(mesh_x), len(mesh_y)))\n",
    "for i, x in enumerate(mesh_x):\n",
    "    for j, y in enumerate(mesh_y):\n",
    "        data_point = np.array([x, y]).reshape(1, 2)\n",
    "        decision_area[i,j] = classifier.predict(data_point)\n",
    "        \n",
    "pcolormesh(mesh_x, mesh_y, decision_area.T, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing SVM with other Classifiers\n",
    "\n",
    "In machine learning, we usually compare various models in order to pick the best one for a particular application. Model comparison is usually done through cross-validation (see above for details about cross-validation). In the context of this course, for the sake of comparison, we compare classification accuracy for two classifiers: the already presented **Linear SVM** (in sklearn: `svm.SVC(kernel='linear')`) and the (very famous) **k-Nearest Neighbour** (in sklearn: `neighbors.KNeighborsClassifier()`)\n",
    "\n",
    "If you don't know kNN, this classification algorithm assigns a label to a new input vector from a majority vote of its k nearest neighbors:\n",
    "\n",
    "![kNN](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png \"kNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import kNN from sklearn and re-import svm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['colors']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['SVM', 'kNN']\n",
    "all_scores = {'SVM': [], 'kNN': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 : SVM score: 100.00%\n",
      "Test 1 : kNN score: 100.00%\n",
      "Test 2 : SVM score: 93.33%\n",
      "Test 2 : kNN score: 93.33%\n",
      "Test 3 : SVM score: 100.00%\n",
      "Test 3 : kNN score: 100.00%\n",
      "Test 4 : SVM score: 100.00%\n",
      "Test 4 : kNN score: 100.00%\n",
      "Test 5 : SVM score: 86.67%\n",
      "Test 5 : kNN score: 86.67%\n",
      "Test 6 : SVM score: 100.00%\n",
      "Test 6 : kNN score: 93.33%\n",
      "Test 7 : SVM score: 93.33%\n",
      "Test 7 : kNN score: 93.33%\n",
      "Test 8 : SVM score: 100.00%\n",
      "Test 8 : kNN score: 100.00%\n",
      "Test 9 : SVM score: 100.00%\n",
      "Test 9 : kNN score: 100.00%\n",
      "Test 10 : SVM score: 100.00%\n",
      "Test 10 : kNN score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "features, labels, colors = get_iris_data()\n",
    "\n",
    "count_tests = 0\n",
    "labels = np.array(labels)\n",
    "for train_index, test_index in splitter.split(features, labels):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = features[train_index]\n",
    "    y_train = labels[train_index]\n",
    "    X_test = features[test_index]\n",
    "    y_test = labels[test_index]   \n",
    "    \n",
    "    count_tests += 1\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM'): classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='kNN'): classifier = neighbors.KNeighborsClassifier()\n",
    "\n",
    "        # train classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test, y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "        # print score\n",
    "        print('Test', count_tests, ':', clf, 'score: %.2f%%'%(score*100)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM mean score: 97.33%\n",
      "kNN mean score: 96.67%\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    print(clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "About this material: copyright Baptiste Caramiaux (write me for any questions or use of this material [email](mailto:baptiste.caramiaux@lri.fr))\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
